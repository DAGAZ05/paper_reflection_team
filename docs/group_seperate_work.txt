各智能体小组细分
组别	角色	人数	核心任务	对应智能体职责 
核心管理层	项目负责人	1	负责进度同步、接口规范制定及全流程集成	全局任务分解与终审决策 
	标准建模	1	将评阅标准其转化为数字化规则	基于用户输入标准生成蓝图 
1. 计划中枢组	路由开发	1	开发动态路由逻辑，根据论文类型匹配评审流	自适应调整调用序列 
	中枢逻辑开发	2	编写 Orchestrator 核心代码，管理任务状态	分解任务、管理状态 
	提示词构建	1	优化中枢智能体的全局决策提示词 (Prompt)	扮演“主考官”进行终审决策 
2. 格式审计组	CV/布局开发	2	利用计算机视觉分析 PDF 布局、图表、公式位置	检测图表关联、公式编号对齐 
	语义判定	1	编写错别字红线判定逻辑（如：全文 > 10个）	通过上下文判定错别字红线 
	数据测试/标注	1	收集排版错误样本，核查引用标注的一致性	核查参考文献引用位置一致性 
3. 逻辑审计组	语义建模	2	利用自然语言推理 (NLI) 构建论文语义图谱	分析论文内在逻辑 
	矛盾检测开发	2	提取摘要与正文数据，识别并触发语义报警	判定摘要、实验与结论间的矛盾 
4. 代码审计组	图谱构建	2	构建存储库智能图谱 (RIG)，解析代码依赖	构建存储库智能图谱 (RIG) 
	架构校验	2	验证论文描述的架构（如微服务）是否在代码中实现	将架构图与代码调用链路对齐 
5. 实验数据组	图像取证	2	识别图表质量，检测是否存在伪造或波动雷同	识别图表伪造、核查图表质量 
	统计评估	2	利用统计学模型评估结论显著性及实验科学性	评估结论显著性、核查实验对比 
6. 文献真实性组	RAG 开发	2	对接 IEEE/Google Scholar 等权威数据库接口	引文与外部权威数据库实时比对 
	真实性校验员	2	检测虚假文献、虚假页码及文献相关性	检测虚假文献/页码、核查权威性 
7. 反思评估组	幻觉评估	2	利用 LLM-as-a-judge 分析其他智能体的客观性	识别由于模型幻觉导致的错判 
	对话/交互开发	2	模拟导师对话，标记“需要人工复核”的项目	模拟“导师”对话、标记人工复核项 

多智能体构建
在多智能体生态系统中，每个智能体被赋予了特定的角色、目标与工具集。以下是针对软件工程论文特性定制的核心智能体矩阵。
1. 计划与调度中枢智能体 (Lead Orchestrator Agent)
该智能体扮演“主考官”的角色，负责全局任务的分解、状态管理及终审决策。它基于用户输入的评审标准（如工程教育认证标准或特定院校标准），生成一个多步评审蓝图 11。它具备动态路由能力，能够根据论文的类型（如：算法改进型或系统开发型）自适应调整下游智能体的调用序列 3。
2. 格式与排版审计智能体 (Standardization Auditor Agent)
该智能体专注于论文的物理结构与规范性核查。其逻辑引擎集成了计算机视觉（CV）与 PDF 布局分析技术，用于检测图表标题与内容的关联、公式编号的右对齐、参考文献的引用位置及标注一致性 5。对于错别字的检测，该智能体通过语义上下文判定错别字是否达到“一页2个以上”或“全文10个以上”的红线标准 7。
3. 深度逻辑一致性智能体 (Deep Logic Auditor Agent)
这是系统中最具技术含量的智能体，利用自然语言推理（NLI）与语义图谱分析论文的内在逻辑 17。它通过提取摘要中的“贡献声明”、正文中的“实验数据”与结论中的“最终评价”，判断是否存在语义矛盾。例如，如果实验部分显示性能提升 20%，而摘要声称提升 50%，该智能体会触发报警机制 17。
4. 存储库级代码审计智能体 (GraphCode Agent)
软件工程硕士论文必须附带实际工程成果。该智能体不只是简单的代码检查，而是通过构建存储库智能图谱（Repository Intelligence Graph, RIG），将论文中的系统架构图与实际代码文件的依赖关系、调用链路进行对齐 20。它能验证论文中声称的“采用了微服务架构”是否在代码中通过具体通信组件得以实现 22。
5. 实验数据与因果智能体 (Empirical Data Agent)
专门针对“优化”和“改进”类论文，该智能体重点检查是否给出了前后实验数据的对比，以及实验设置的科学性 7。它会核查图表的质量，识别图表是否存在伪造嫌疑（如不同实验条件的波动曲线完全一致），并利用统计学模型评估结论的显著性。
6. 参考文献真实性智能体 (Citation Integrity Agent)
通过 RAG 技术，该智能体将引文与外部权威数据库（如 Google Scholar, IEEE Xplore）进行实时比对，检测是否存在虚假文献、虚假页码或文献与引用点不相关的问题 23。它同时核查引文的权威性，确保其遵循“引用亲自阅读过且具有参考价值的文献”之原则。
7. 反思与评估智能体 (Self-Reflection Judge Agent)
作为质量保险层，该智能体对其他所有智能体的初步意见进行二次审计。它利用 LLM-as-a-judge 模式，分析评审意见的客观性与准确性，识别由于模型幻觉导致的错误判断 13。它会模拟“导师”与“系统”之间的对话，对不确定的评审项标记为“需要人工复核” 1。
🤖
小组	核心 Python 库	开发重点
1. 计划中枢组	LangGraph / Flask	编写“状态机”，决定论文该流向哪个智能体 。
2. 格式审计组	PyMuPDF / OpenCV	利用 PDF 解析技术提取坐标，核查图表和公式位置 。
3. 逻辑审计组	Transformers (NLI)	提取关键句，对比摘要与实验数据是否存在语义矛盾 。
4. 代码审计组	NetworkX / Tree-sitter	构建代码依赖图 (RIG)，核查代码架构是否真实 。
5. 实验数据组	Pandas / Scipy	利用统计学模型评估结论显著性，识别异常一致的曲线 。
6. 文献真实性组	FAISS / Requests	通过 RAG 技术对接 API，实时比对引文真实性 。
7. 反思评估组	OpenAI API / LiteLLM	编写高质量的 Judge Prompt，纠正模型幻觉 。